##STREAMLIT ELEMENTS
# x = st.text_input("How are you?")

# is_clicked = st.button("Click Me")

# if is_clicked:
#     st.write(f"You replied: {x}")

# st.title("Streamlit Example")


# # something = title 
# st.write("""
# # Explore different classifier 
# Which one is the best?         
# """)

# #st.selectbox() is within the page; st.sidebar.selectbox() is on the sidebar
#classifier_name = st.sidebar.selectbox("Select Classifier", ("KNN", "SVM", "Random Forest"))
# dataset_choice = st.sidebar.selectbox("Select Dataset", ("Iris", "Breast Cancer", "Wine"))
# st.write(f"You have chosen {dataset_choice} as the dataset.")

import streamlit as st 
from streamlit_lottie import st_lottie
import lottie_animations as l
import pickle
from urllib.parse import urlparse
from tld import get_tld, is_tld
import numpy as np
import feature_extraction_script as fe

st.set_page_config(page_title="URL Classification", page_icon="üõ°Ô∏è", layout="wide")

def page_intro_section():
    ##Page introduction section
    col1, col2 = st.columns([1,1])
    with col1:
        st.title("Welcome to the URL Classification page !")
        st.subheader("Reveal what‚Äôs behind the URL ‚Äî identify threats, scams, and unsafe content with AI-powered classification. ü§ñ")
    with col2:
        st_lottie(l.mainpage_lottie, loop = True, width = 300, height = 300, key = None)
        
def model_selection():
    model_choice = st.selectbox("#### Select Model:", ("Random Forest", "XGBoost"))
    if model_choice == "Random Forest":
        model = pickle.load(open(r"Models\rf_classifier.pkl", "rb"))
    elif model_choice == "XGBoost":
        model = pickle.load(open(r"Models\xgboost_classifier.pkl", "rb"))

    st.write(f"‚öôÔ∏è Current model engine: **{model_choice}** ‚öôÔ∏è")
    
    return model 

def url_input_section():
    url = st.text_input("#### Insert the web address ‚¨áÔ∏è", placeholder="http://maliciouswebsitetest.com")
    
    with st.expander("Explore URL features that are extracted for classification"):
        col_a, col_b = st.columns([1, 1])
        with col_a:
            st.write("- **URL Abnormality**: The URL is checked for any abnormalities or suspicious patterns.")
            st.write("- **https existence**: The URL is checked for the existence of HTTPS, which is a secure version of HTTP.")
            st.write("- **Shortening service**: The URL is checked for the use of URL shortening services, which can hide the true destination of the link.")    
            st.write("- **IP Address**: The URL is checked for the presence of an IP address, which can indicate a potential threat.")
            st.write("- **Special Characters Count**: The URL is checked for the number of various special characters (@,?,-,=,#...), which can indicate a potential threat.")
        with col_b:
            st.write("- **Letters Count**: An unusually high number of letters may suggest obfuscation tactics used to mimic legitimate domains.")
            st.write("- **Digits Count**: Excessive digits in a URL often indicate autogenerated links, which are common in phishing or scam campaigns.")
            st.write("- **Length**: Very long URLs may be used to hide malicious payloads or mislead users with deceptive structures.")
            st.write("- **URL Region**: The geographical origin or domain suffix (e.g., `.ru`, `.cn`) can sometimes correlate with suspicious hosting practices or known threat sources.")
            st.write("- **Secondary Domain**: The presence of unexpected or excessive subdomains (e.g., `login.bank.example.com`) may be an attempt to impersonate trusted websites.")

    return url

def validate_url(url):
    # Check if URL is empty
    if not url:
        return False, "Please enter a URL"
    
    # Check for protocol (http/https)
    if not (url.startswith('http://') or url.startswith('https://')):
        return False, "URL must start with http:// or https://"
    
    try:
        # Attempt to extract TLD
        res = get_tld(url, as_object=True, fail_silently=True)
        
        if res is None:
            return False, "Invalid or missing top-level domain"
            
        # Parse URL to validate structure
        parsed = urlparse(url)
        if not all([parsed.scheme, parsed.netloc]):
            return False, "Invalid URL structure"
            
        return True, "Valid URL"
        
    except Exception as e:
        return False, "Invalid URL format"

page_intro_section()
st.divider()
st.write("*Prediction is not fully accurate. The prediction accuracy on real world data is solely based on the values provided in the dataset.")
st.write("However, you may still find its predictions useful by testing the URLs from these legitimate websites:")
st.write("https://phishtank.org/, https://urlhaus.abuse.ch/browse/, https://badssl.com/")

model = model_selection()
url = url_input_section()

button_clicked = st.button("üîç Check URL")

if button_clicked: 
    is_valid, message = validate_url(url)
    if not is_valid:
        st.error(message)
    else:
        with st.spinner('Analyzing URL...'):
            try:
                #Extract features from URL
                features_df = fe.extract_url_features(url)
                
                #Model prediction
                prediction = model.predict(features_df)
                
                #Success message
                st.success("Analysis Complete!")
                
                # Label mapping for XGBoost encoded predictions
                label_mapping = {
                    0: "benign",
                    1: "defacement",
                    2: "malware",
                    3: "phishing"
                }
                
                ## XGBoost label is in numeric form, so converting to string label is necessary
                # Convert numeric prediction to string label if using XGBoost
                if isinstance(prediction[0], (int, np.integer)):
                    pred_label = label_mapping[prediction[0]]
                else:
                    pred_label = prediction[0]
                
                # Determine threat type based on prediction
                if pred_label == "benign":
                    st.success("‚úÖ Benign URL: This website appears to be safe")
                    threat_type = "Benign"
                elif pred_label == "defacement":
                    st.error("‚ö†Ô∏è Defacement Threat Detected!")
                    threat_type = "Defacement"
                elif pred_label == "malware":
                    st.error("‚ò¢Ô∏è Malware Threat Detected!")
                    threat_type = "Malware"
                elif pred_label == "phishing":
                    st.error("üé£ Phishing Threat Detected!")
                    threat_type = "Phishing"
                
                #Show details in expander
                with st.expander(f"Why is this URL classified as {threat_type}?"):
                    st.dataframe(features_df)
                    st.markdown("""
                    **Threat Categories:**
                    - **Benign**: Safe, legitimate websites
                    - **Defacement**: Unauthorized modifications to website appearance
                    - **Phishing**: Attempts to steal sensitive information
                    - **Malware**: Contains harmful software
                    """)   
            except Exception as e:
                st.error(f"Error during analysis: {str(e)}")
        